{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76259786-ea11-4eac-a6f8-090ec00bca09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::CPUDevice) (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Lux,\n",
    "    Optimisers,\n",
    "    Random,\n",
    "    Printf,\n",
    "    Statistics,\n",
    "    MLUtils,\n",
    "    Reactant,\n",
    "    Enzyme\n",
    "\n",
    "const xdev = reactant_device(; force=true)\n",
    "const cdev = cpu_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1a80ba-71e4-44e7-bf88-2de9c9afa884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PINN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct PINN{M} <: AbstractLuxWrapperLayer{:model}\n",
    "    model::M\n",
    "end\n",
    "\n",
    "function PINN(; hidden_dims::Int=32)\n",
    "    return PINN(\n",
    "        Chain(\n",
    "            Dense(3 => hidden_dims, tanh),\n",
    "            Dense(hidden_dims => hidden_dims, tanh),\n",
    "            Dense(hidden_dims => hidden_dims, tanh),\n",
    "            Dense(hidden_dims => 1),\n",
    "        ),\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efb6bab-210b-431c-843a-03b7bf263fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∂²u_∂y² (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function u(model::StatefulLuxLayer, xyt::AbstractArray)\n",
    "    return model(xyt)\n",
    "end\n",
    "\n",
    "function ∂u_∂t(model::StatefulLuxLayer, xyt::AbstractArray)\n",
    "    return Enzyme.gradient(Enzyme.Reverse, sum ∘ model, xyt)[1][3, :]\n",
    "end\n",
    "\n",
    "function ∂u_∂x(model::StatefulLuxLayer, xyt::AbstractArray)\n",
    "    return Enzyme.gradient(Enzyme.Reverse, sum ∘ model, xyt)[1][1, :]\n",
    "end\n",
    "\n",
    "function ∂u_∂y(model::StatefulLuxLayer, xyt::AbstractArray)\n",
    "    return Enzyme.gradient(Enzyme.Reverse, sum ∘ model, xyt)[1][2, :]\n",
    "end\n",
    "\n",
    "function ∂²u_∂x²(model::StatefulLuxLayer, xyt::AbstractArray)\n",
    "    return Enzyme.gradient(Enzyme.Reverse, sum ∘ ∂u_∂x, Enzyme.Const(model), xyt)[2][1, :]\n",
    "end\n",
    "\n",
    "function ∂²u_∂y²(model::StatefulLuxLayer, xyt::AbstractArray)\n",
    "    return Enzyme.gradient(Enzyme.Reverse, sum ∘ ∂u_∂y, Enzyme.Const(model), xyt)[2][2, :]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839b5637-81c7-4ae2-b3c1-39d6f2ef5133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_function (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function physics_informed_loss_function(model::StatefulLuxLayer, xyt::AbstractArray)\n",
    "    return mean(abs2, ∂u_∂t(model, xyt) .- u(model, xyt) .* ∂²u_∂x²(model, xyt) .- ∂²u_∂y²(model, xyt))\n",
    "end\n",
    "function mse_loss_function(model::StatefulLuxLayer, target::AbstractArray, xyt::AbstractArray)\n",
    "    return MSELoss()(model(xyt), target)\n",
    "end\n",
    "function loss_function(model, ps, st, (xyt, target_data, xyt_bc, target_bc))\n",
    "    smodel = StatefulLuxLayer(model, ps, st)\n",
    "    physics_loss = physics_informed_loss_function(smodel, xyt)\n",
    "    data_loss = mse_loss_function(smodel, target_data, xyt)\n",
    "    bc_loss = mse_loss_function(smodel, target_bc, xyt_bc)\n",
    "    loss = physics_loss + data_loss + bc_loss\n",
    "    return loss, smodel.st, (; physics_loss, data_loss, bc_loss)\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff8f917-c5de-49f0-ab5b-dd9ea5cb7e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "analytical_solution (generic function with 2 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytical_solution(x, y, t) = @. exp(x + y) * cos(x + y + 4t)\n",
    "analytical_solution(xyt) = analytical_solution(xyt[1, :], xyt[2, :], xyt[3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8b130f-a415-4e2c-aeb9-5f20323ad596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×4096 Matrix{Float32}:\n",
       " 0.511  0.512222  0.513394  0.514452  …  0.761361  0.839134  0.926969"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin\n",
    "    grid_len = 16\n",
    "\n",
    "    grid = range(0.0f0, 2.0f0; length=grid_len)\n",
    "    xyt = stack([[elem...] for elem in vec(collect(Iterators.product(grid, grid, grid)))])\n",
    "\n",
    "    target_data = reshape(analytical_solution(xyt), 1, :)\n",
    "\n",
    "    bc_len = 512\n",
    "\n",
    "    x = collect(range(0.0f0, 2.0f0; length=bc_len))\n",
    "    y = collect(range(0.0f0, 2.0f0; length=bc_len))\n",
    "    t = collect(range(0.0f0, 2.0f0; length=bc_len))\n",
    "\n",
    "    xyt_bc = hcat(\n",
    "        stack((x, y, zeros(Float32, bc_len)); dims=1),\n",
    "        stack((zeros(Float32, bc_len), y, t); dims=1),\n",
    "        stack((ones(Float32, bc_len) .* 2, y, t); dims=1),\n",
    "        stack((x, zeros(Float32, bc_len), t); dims=1),\n",
    "        stack((x, ones(Float32, bc_len) .* 2, t); dims=1),\n",
    "    )\n",
    "    target_bc = reshape(analytical_solution(xyt_bc), 1, :)\n",
    "\n",
    "    min_target_bc, max_target_bc = extrema(target_bc)\n",
    "    min_data, max_data = extrema(target_data)\n",
    "    min_pde_val, max_pde_val = min(min_data, min_target_bc), max(max_data, max_target_bc)\n",
    "\n",
    "    xyt = (xyt .- minimum(xyt)) ./ (maximum(xyt) .- minimum(xyt))\n",
    "    xyt_bc = (xyt_bc .- minimum(xyt_bc)) ./ (maximum(xyt_bc) .- minimum(xyt_bc))\n",
    "    target_bc = (target_bc .- min_pde_val) ./ (max_pde_val - min_pde_val)\n",
    "    target_data = (target_data .- min_pde_val) ./ (max_pde_val - min_pde_val)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3285a43-f5c8-4cb1-96f5-4e51b5f83a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757270412.409325   11786 service.cc:163] XLA service 0x38914110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1757270412.409346   11786 service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "I0000 00:00:1757270412.409669   11786 se_gpu_pjrt_client.cc:1338] Using BFC allocator.\n",
      "I0000 00:00:1757270412.409699   11786 gpu_helpers.cc:136] XLA backend allocating 6159925248 bytes on device 0 for BFCAllocator.\n",
      "I0000 00:00:1757270412.409725   11786 gpu_helpers.cc:177] XLA backend will use up to 2053308416 bytes on device 0 for CollectiveBFCAllocator.\n",
      "I0000 00:00:1757270412.421045   11786 cuda_dnn.cc:463] Loaded cuDNN version 90800\n"
     ]
    }
   ],
   "source": [
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 0)\n",
    "pinn = PINN(; hidden_dims=10)\n",
    "ps, st = Lux.setup(rng, pinn) |> xdev\n",
    "train_state = Training.TrainState(pinn, ps, st, Adam(0.005f0))\n",
    "\n",
    "xyt_batch = xyt[:, 1:40] |> xdev\n",
    "target_data_batch = target_data[:, 1:40] |> xdev\n",
    "xyt_bc_batch = xyt_bc[:, 1:40] |> xdev\n",
    "target_bc_batch = target_bc[:, 1:40] |> xdev\n",
    "\n",
    "_, loss, stats, train_state = Training.single_train_step!(\n",
    "        AutoEnzyme(),\n",
    "        loss_function,\n",
    "        (xyt_batch, target_data_batch, xyt_bc_batch, target_bc_batch),\n",
    "        train_state;\n",
    "        return_gradients=Val(false),\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57b5f76d-b191-4931-8389-a41f6bc07e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1000, loss: 0.016553883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757266283.547096    7194 service.cc:163] XLA service 0x322e16c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1757266283.547117    7194 service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "I0000 00:00:1757266283.547477    7194 se_gpu_pjrt_client.cc:1338] Using BFC allocator.\n",
      "I0000 00:00:1757266283.547566    7194 gpu_helpers.cc:136] XLA backend allocating 6159925248 bytes on device 0 for BFCAllocator.\n",
      "I0000 00:00:1757266283.547635    7194 gpu_helpers.cc:177] XLA backend will use up to 2053308416 bytes on device 0 for CollectiveBFCAllocator.\n",
      "I0000 00:00:1757266283.558691    7194 cuda_dnn.cc:463] Loaded cuDNN version 90800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2000, loss: 0.014384383\n",
      "Iter: 3000, loss: 0.01110726\n",
      "Iter: 4000, loss: 0.00680809\n",
      "Iter: 5000, loss: 0.009741962\n",
      "Iter: 6000, loss: 0.00096959283\n",
      "Iter: 7000, loss: 0.0009281422\n",
      "Iter: 8000, loss: 0.0013213546\n",
      "Iter: 9000, loss: 0.0005148426\n",
      "Iter: 10000, loss: 0.0009806744\n",
      "Iter: 11000, loss: 0.00036486753\n",
      "Iter: 12000, loss: 0.000426544\n",
      "Iter: 13000, loss: 0.0002843058\n",
      "Iter: 14000, loss: 0.0004991124\n",
      "Iter: 15000, loss: 0.00025018654\n",
      "Iter: 16000, loss: 0.00031640788\n",
      "Iter: 17000, loss: 0.00039353993\n",
      "Iter: 18000, loss: 0.00031272764\n",
      "Iter: 19000, loss: 0.0002892317\n",
      "Iter: 20000, loss: 0.00024611966\n",
      "Iter: 21000, loss: 0.00022522072\n",
      "Iter: 22000, loss: 0.00023999666\n",
      "Iter: 23000, loss: 0.0003094984\n",
      "Iter: 24000, loss: 0.0002671322\n",
      "Iter: 25000, loss: 0.00018351548\n",
      "Iter: 26000, loss: 0.00035562256\n",
      "Iter: 27000, loss: 0.00019729715\n",
      "Iter: 28000, loss: 0.0002448506\n",
      "Iter: 29000, loss: 0.0002386901\n",
      "Iter: 30000, loss: 0.00020195781\n",
      "Iter: 31000, loss: 0.00017870276\n",
      "Iter: 32000, loss: 0.00021166826\n",
      "Iter: 33000, loss: 0.00020950695\n",
      "Iter: 34000, loss: 0.00023810394\n",
      "Iter: 35000, loss: 0.00019887718\n",
      "Iter: 36000, loss: 0.00021829737\n",
      "Iter: 37000, loss: 0.00016938779\n",
      "Iter: 38000, loss: 0.00014128399\n",
      "Iter: 39000, loss: 0.00015988905\n",
      "Iter: 40000, loss: 0.00017916108\n",
      "Iter: 41000, loss: 0.00020034483\n",
      "Iter: 42000, loss: 0.00018911394\n",
      "Iter: 43000, loss: 0.00017615274\n",
      "Iter: 44000, loss: 0.00017592685\n",
      "Iter: 45000, loss: 0.00017372382\n",
      "Iter: 46000, loss: 0.00020014275\n",
      "Iter: 47000, loss: 0.0001855357\n",
      "Iter: 48000, loss: 0.00023440373\n",
      "Iter: 49000, loss: 0.00013331082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StatefulLuxLayer{Val{true}()}(\n",
       "    PINN(\n",
       "        model = Chain(\n",
       "            layer_1 = Dense(3 => 128, tanh),      \u001b[90m# 512 parameters\u001b[39m\n",
       "            layer_(2-3) = Dense(128 => 128, tanh),  \u001b[90m# 33_024 (16_512 x 2) parameters\u001b[39m\n",
       "            layer_4 = Dense(128 => 1),            \u001b[90m# 129 parameters\u001b[39m\n",
       "        ),\n",
       "    ),\n",
       ") \u001b[90m        # Total: \u001b[39m33_665 parameters,\n",
       "\u001b[90m          #        plus \u001b[39m0 states."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_model(xyt, target_data, xyt_bc, target_bc; seed::Int=0, maxiters::Int=50000, hidden_dims::Int=128)\n",
    "    rng = Random.default_rng()\n",
    "    Random.seed!(rng, seed)\n",
    "\n",
    "    pinn = PINN(; hidden_dims)\n",
    "    ps, st = Lux.setup(rng, pinn) |> xdev\n",
    "\n",
    "    bc_dataloader = DataLoader((xyt_bc, target_bc); batchsize=128, shuffle=true, partial=false) |> xdev\n",
    "    pde_dataloader = DataLoader((xyt, target_data); batchsize=128, shuffle=true, partial=false) |> xdev\n",
    "\n",
    "    train_state = Training.TrainState(pinn, ps, st, Adam(0.005f0))\n",
    "\n",
    "    lr = i -> i < 5000 ? 0.005f0 : (i < 10000 ? 0.0005f0 : 0.00005f0)\n",
    "\n",
    "    iter = 1\n",
    "    for ((xyt_batch, target_data_batch), (xyt_bc_batch, target_bc_batch)) in\n",
    "        zip(Iterators.cycle(pde_dataloader), Iterators.cycle(bc_dataloader))\n",
    "        Optimisers.adjust!(train_state, lr(iter))\n",
    "\n",
    "        _, loss, stats, train_state = Training.single_train_step!(\n",
    "            AutoEnzyme(),\n",
    "            loss_function,\n",
    "            (xyt_batch, target_data_batch, xyt_bc_batch, target_bc_batch),\n",
    "            train_state;\n",
    "            return_gradients=Val(false),\n",
    "        )\n",
    "\n",
    "        if iter % 1000 == 0\n",
    "            println(\"Iter: $(iter), loss: $(Float32(loss))\")\n",
    "        end\n",
    "        \n",
    "        iter += 1\n",
    "        iter ≥ maxiters && break\n",
    "    end\n",
    "\n",
    "    return StatefulLuxLayer(pinn, cdev(train_state.parameters), cdev(train_state.states))\n",
    "end\n",
    "\n",
    "trained_model = train_model(xyt, target_data, xyt_bc, target_bc)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74553bea-e376-4c19-97ed-1123a7bc7a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×4 Matrix{Float32}:\n",
       " 1.57821  1.97627  1.85081  1.96543"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = [1.0f0 2.0f0 3.0f0 1.0f0;\n",
    "       1.1f0 2.1f0 3.1f0 4.1f0;\n",
    "       1.2f0 2.2f0 3.2f0 4.2f0]\n",
    "trained_model(dat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
